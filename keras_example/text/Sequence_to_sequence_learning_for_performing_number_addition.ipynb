{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence to sequence learning for performing number addition\n",
    "Description: A model that learns to add strings of numbers, e.g. \"535+61\" -> \"596\".\n",
    "In this example, we train a model to learn to add two numbers, provided as strings.\n",
    "\n",
    "Example:\n",
    "\n",
    "Input: \"535+61\"\n",
    "Output: \"596\"\n",
    "Input may optionally be reversed, which was shown to increase performance in many tasks in: Learning to Execute and [Sequence to Sequence Learning with Neural Networks](\n",
    "\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)\n",
    "\n",
    "Theoretically, sequence order inversion introduces shorter term dependencies between source and target for this problem.\n",
    "\n",
    "Results:\n",
    "\n",
    "For two digits (reversed):\n",
    "\n",
    "One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "Three digits (reversed):\n",
    "\n",
    "One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "Four digits (reversed):\n",
    "\n",
    "One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "Five digits (reversed):\n",
    "\n",
    "One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total questions: 50000\n"
     ]
    }
   ],
   "source": [
    "#Generate the data\n",
    "class CharacterTable:\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one-hot integer representation\n",
    "    + Decode the one-hot or integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One-hot encode given string C.\n",
    "        # Arguments\n",
    "            C: string, to be encoded.\n",
    "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"Decode the given vector or 2D array to their character output.\n",
    "        # Arguments\n",
    "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = \"0123456789+ \"\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print(\"Generating data...\")\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(\n",
    "        \"\".join(\n",
    "            np.random.choice(list(\"0123456789\"))\n",
    "            for i in range(np.random.randint(1, DIGITS + 1))\n",
    "        )\n",
    "    )\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = \"{}+{}\".format(a, b)\n",
    "    query = q + \" \" * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print(\"Total questions:\", len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "#Vectorize the data\n",
    "print(\"Vectorization...\")\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print(\"Training Data:\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"Validation Data:\")\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build the model\n",
    "print(\"Build model...\")\n",
    "num_layers = 1  # Try to add more LSTM layers!\n",
    "\n",
    "model = keras.Sequential()\n",
    "# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last output of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(num_layers):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(layers.LSTM(128, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.7447 - accuracy: 0.3603 - val_loss: 1.5453 - val_accuracy: 0.4209\n",
      "Q 642+300 T 942  ☒ 111 \n",
      "Q 767+777 T 1544 ☒ 1577\n",
      "Q 401+171 T 572  ☒ 519 \n",
      "Q 4+64    T 68   ☒ 14  \n",
      "Q 60+65   T 125  ☒ 164 \n",
      "Q 676+10  T 686  ☒ 771 \n",
      "Q 6+853   T 859  ☒ 874 \n",
      "Q 64+86   T 150  ☒ 164 \n",
      "Q 922+854 T 1776 ☒ 1799\n",
      "Q 87+705  T 792  ☒ 871 \n",
      "\n",
      "Iteration 2\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3460 - accuracy: 0.4950 - val_loss: 1.1801 - val_accuracy: 0.5605\n",
      "Q 912+40  T 952  ☒ 941 \n",
      "Q 532+2   T 534  ☒ 536 \n",
      "Q 787+5   T 792  ☒ 787 \n",
      "Q 918+73  T 991  ☒ 901 \n",
      "Q 278+495 T 773  ☒ 801 \n",
      "Q 446+35  T 481  ☑ 481 \n",
      "Q 1+926   T 927  ☒ 920 \n",
      "Q 764+32  T 796  ☒ 791 \n",
      "Q 90+0    T 90   ☑ 90  \n",
      "Q 40+759  T 799  ☒ 777 \n",
      "\n",
      "Iteration 3\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.0697 - accuracy: 0.6016 - val_loss: 1.0312 - val_accuracy: 0.5985\n",
      "Q 45+76   T 121  ☒ 111 \n",
      "Q 22+576  T 598  ☒ 595 \n",
      "Q 868+874 T 1742 ☒ 1655\n",
      "Q 928+621 T 1549 ☒ 1555\n",
      "Q 83+36   T 119  ☒ 115 \n",
      "Q 65+117  T 182  ☒ 175 \n",
      "Q 188+98  T 286  ☒ 271 \n",
      "Q 189+157 T 346  ☒ 345 \n",
      "Q 98+520  T 618  ☒ 611 \n",
      "Q 46+11   T 57   ☒ 55  \n",
      "\n",
      "Iteration 4\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9001 - accuracy: 0.6652 - val_loss: 0.8510 - val_accuracy: 0.6797\n",
      "Q 753+903 T 1656 ☒ 1698\n",
      "Q 152+65  T 217  ☒ 219 \n",
      "Q 828+146 T 974  ☒ 976 \n",
      "Q 25+625  T 650  ☒ 659 \n",
      "Q 837+866 T 1703 ☒ 1610\n",
      "Q 822+242 T 1064 ☒ 1053\n",
      "Q 659+69  T 728  ☒ 738 \n",
      "Q 397+19  T 416  ☒ 419 \n",
      "Q 85+560  T 645  ☒ 648 \n",
      "Q 909+53  T 962  ☒ 966 \n",
      "\n",
      "Iteration 5\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7850 - accuracy: 0.7100 - val_loss: 0.7493 - val_accuracy: 0.7272\n",
      "Q 199+5   T 204  ☒ 202 \n",
      "Q 41+98   T 139  ☒ 134 \n",
      "Q 687+532 T 1219 ☒ 1212\n",
      "Q 65+766  T 831  ☒ 839 \n",
      "Q 4+2     T 6    ☒ 4   \n",
      "Q 3+803   T 806  ☒ 803 \n",
      "Q 99+29   T 128  ☒ 136 \n",
      "Q 904+10  T 914  ☒ 917 \n",
      "Q 735+666 T 1401 ☒ 1402\n",
      "Q 758+51  T 809  ☒ 808 \n",
      "\n",
      "Iteration 6\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7004 - accuracy: 0.7453 - val_loss: 0.6584 - val_accuracy: 0.7574\n",
      "Q 478+752 T 1230 ☒ 1231\n",
      "Q 90+0    T 90   ☒ 96  \n",
      "Q 969+387 T 1356 ☒ 1361\n",
      "Q 939+30  T 969  ☒ 961 \n",
      "Q 480+481 T 961  ☒ 966 \n",
      "Q 0+169   T 169  ☒ 168 \n",
      "Q 420+25  T 445  ☒ 446 \n",
      "Q 804+64  T 868  ☑ 868 \n",
      "Q 23+884  T 907  ☒ 906 \n",
      "Q 48+385  T 433  ☒ 432 \n",
      "\n",
      "Iteration 7\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.5221 - accuracy: 0.8121 - val_loss: 0.3921 - val_accuracy: 0.8629\n",
      "Q 8+392   T 400  ☒ 300 \n",
      "Q 885+46  T 931  ☑ 931 \n",
      "Q 116+556 T 672  ☒ 662 \n",
      "Q 254+259 T 513  ☑ 513 \n",
      "Q 5+416   T 421  ☑ 421 \n",
      "Q 281+555 T 836  ☑ 836 \n",
      "Q 963+544 T 1507 ☑ 1507\n",
      "Q 87+953  T 1040 ☒ 1030\n",
      "Q 49+631  T 680  ☒ 670 \n",
      "Q 913+372 T 1285 ☒ 1276\n",
      "\n",
      "Iteration 8\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.2881 - accuracy: 0.9111 - val_loss: 0.2388 - val_accuracy: 0.9254\n",
      "Q 5+211   T 216  ☒ 215 \n",
      "Q 76+717  T 793  ☑ 793 \n",
      "Q 441+466 T 907  ☑ 907 \n",
      "Q 744+425 T 1169 ☑ 1169\n",
      "Q 910+186 T 1096 ☒ 1086\n",
      "Q 42+360  T 402  ☑ 402 \n",
      "Q 812+21  T 833  ☒ 832 \n",
      "Q 1+300   T 301  ☑ 301 \n",
      "Q 510+40  T 550  ☒ 551 \n",
      "Q 29+328  T 357  ☑ 357 \n",
      "\n",
      "Iteration 9\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 0.1703 - accuracy: 0.9557 - val_loss: 0.1607 - val_accuracy: 0.9509\n",
      "Q 939+63  T 1002 ☑ 1002\n",
      "Q 528+20  T 548  ☑ 548 \n",
      "Q 141+63  T 204  ☑ 204 \n",
      "Q 39+83   T 122  ☑ 122 \n",
      "Q 15+53   T 68   ☑ 68  \n",
      "Q 58+839  T 897  ☑ 897 \n",
      "Q 43+443  T 486  ☑ 486 \n",
      "Q 31+626  T 657  ☑ 657 \n",
      "Q 28+247  T 275  ☑ 275 \n",
      "Q 446+33  T 479  ☑ 479 \n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for epoch in range(1, epochs):\n",
    "    print()\n",
    "    print(\"Iteration\", epoch)\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val, y_val),\n",
    "    )\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
    "        print(\"T\", correct, end=\" \")\n",
    "        if correct == guess:\n",
    "            print(\"☑ \" + guess)\n",
    "        else:\n",
    "            print(\"☒ \" + guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
