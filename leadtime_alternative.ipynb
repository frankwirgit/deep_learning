{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# compute FDR\n",
    "# define FDR: numerator: the false positive alerts / denominator: the base alerts\n",
    "\n",
    "# 1. FDR_org\n",
    "# define base alert using less restricted rule: keep all alerts for FDR_org\n",
    "#\n",
    "# 2. FDR\n",
    "# define base alert using more restricted rule: \n",
    "# keep those alerts with no-missing in its 4-hour prediction window for FDR\n",
    "# drop those alerts with any length of missings, including a single missing\n",
    "#\n",
    "\n",
    "##########################\n",
    "# compute leadtime\n",
    "\n",
    "# define base alert using more restricted rule: \n",
    "# keep those alerts with no-missing in its 4-hour prediction window for FDR\n",
    "# drop those alerts with any length of missings, including a single missing\n",
    "# also drop those alerts entering the hypo episode with leadtime=0\n",
    "\n",
    "# compute the interval between the alert and the first hypoSG (<70mgdL) ecountered in its 4-hr prediction window\n",
    "# keep the first/earliest alert if multiple alerts have linked to the same hypoSG, drop the rest renewed ones\n",
    "\n",
    "# define leadtime: the average of interval of all the kept alerts\n",
    "\n",
    "##########################\n",
    "\n",
    "# data source:\n",
    "#run for every user based on the weekly production pull alert data is based on streams table, sg data is based on the feature vector table\n",
    "\n",
    "##########################\n",
    "\n",
    "# resulted summary statistics:\n",
    "\n",
    "# person_id\n",
    "# numb_total_alert - total number of alerts\n",
    "# avg_alert_lag - average interval between two consecutive alerts\n",
    "# stdv_alert_lag - standard deviation of alert interval\n",
    "# numb_alert_missingSG - number of alerts having missing SG in the 4-hr window\n",
    "# pct_missing_watchup - averge of percentage of missing SG in the 4-hr window\n",
    "# numb_alert_non_missingSG - number of alerts having full 48 SGs in the 4-hr window, no missing\n",
    "# numb_fp_alert_org - number of false positive alerts among all alerts - those ones don't get the hypo SG found in the 4-hr window\n",
    "# FDR_org - FDR based on all alerts\n",
    "# numb_fp_alert - number of false positive alerts among alerts with non-missingSG window - those ones don't get the hypo SG found in the 4-hr window\n",
    "# FDR - FDR based on alerts with non-missingSG window\n",
    "# nonrenew-lag - lagging intervals between two non-renewed alerts\n",
    "# pct_renew_tp_alert - average of percentage of renewed true positive alerts - those ones have hypo SG found in the 4-hr window but it's the same hypo SG predicted by the previous or earlier alert\n",
    "# numb_tp_alert - number of true positive alerts - excluding renewed alerts\n",
    "# avg_leadtime - the average of the lead time among non-renewed alerts\n",
    "\n",
    "\n",
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lcao@us.ibm.com/Downloads/r3_production_analysis/input/50788056_alert_db2.csv\n",
      "numb_total_alert= 20 avg_alert_lag= 324.255 stdv_alert_lag= 420.7006834572574\n",
      "pct_missing_watchup= 8.645833333333334\n",
      "numb_alert_missingSG= 4\n",
      "numb_fp_alert_org= 4 numb_fp_alert= 4 numb_alert_non_missingSG= 16 FDR_org= 20.0 FDR= 25.0\n",
      "nonrenew_lag= 649.3854166666666\n",
      "pct_renew_tp_alert= 25.0\n",
      "avg_leadtime= 64.16388888888889 numb_tp_alert= 6\n",
      "  person_id  numb_total_alert  avg_alert_lag  stdv_alert_lag  \\\n",
      "0  50788056                20        324.255      420.700683   \n",
      "\n",
      "   numb_alert_missingSG  pct_missing_watchup  numb_alert_non_missingSG  \\\n",
      "0                     4             8.645833                        16   \n",
      "\n",
      "   numb_fp_alert_org  FDR_org  numb_fp_alert   FDR  nonrenew_lag  \\\n",
      "0                  4     20.0              4  25.0    649.385417   \n",
      "\n",
      "   pct_renew_tp_alert  numb_tp_alert  avg_leadtime  \n",
      "0                25.0              6     64.163889  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "src=\"/Users/lcao@us.ibm.com/Downloads/r3_production_analysis/input/\"\n",
    "dst=\"/Users/lcao@us.ibm.com/Downloads/r3_production_analysis/output/\"\n",
    "\n",
    "\n",
    "def compute_epoch_alert(s):\n",
    "    return (int(time.mktime(time.strptime(s, \"%Y-%m-%dT%H:%M:%SZ\"))))\n",
    "\n",
    "def compute_epoch_vector(s):\n",
    "    a = int(time.mktime(time.strptime(s[0:19], \"%Y-%m-%dT%H:%M:%S\")))\n",
    "    return (a - 3600*int(s[19:22]))\n",
    "\n",
    "def check_watchup_drop_missing(e):\n",
    "    pct_missing_watchup = np.nan\n",
    "    has_missing=np.nan\n",
    "    hypoSG_watchup=np.nan\n",
    "    leadtime_watchup=np.nan\n",
    "    first_hypoSG=np.nan\n",
    "    epoch = e\n",
    "    \n",
    "    dt = dv[(dv['epoch']>=e) & (dv['epoch']<=(e+4*3600))]\n",
    "    \n",
    "    if(dt.shape[0]>0):\n",
    "        has_missing = 0\n",
    "        pct_missing_watchup=(1-dt.shape[0]/48)*100.\n",
    "        if(pct_missing_watchup<0):\n",
    "            pct_missing_watchup=0.\n",
    "        if(pct_missing_watchup>0):\n",
    "            has_missing = 1\n",
    "\n",
    "        if(has_missing==0):  #only compute lead time for alert without SG missing in the watchup window\n",
    "            \n",
    "            if(dt['hypoSG'].sum()>0):\n",
    "                hypoSG_watchup=1\n",
    "                first_hypoSG = dt[dt['hypoSG']==1].reset_index()['epoch'][0]\n",
    "                leadtime_watchup=(first_hypoSG-e)/60.\n",
    "            else:\n",
    "                hypoSG_watchup=0\n",
    "\n",
    "    return ([epoch, has_missing, pct_missing_watchup,hypoSG_watchup,first_hypoSG,leadtime_watchup])\n",
    "\n",
    "\n",
    "for filename in glob.iglob(src+\"*_alert_db2.csv\", recursive=True):\n",
    "    print(filename)\n",
    "    person_id=filename.replace(src,'').replace(\"_alert_db2.csv\",'')\n",
    "    da = pd.read_csv(src+person_id+\"_alert_db2.csv\",dtype=object)\n",
    "    da = da[['userid','alert_start']]\n",
    "    os.environ['TZ']='UTC' \n",
    "    da['epoch']=da['alert_start'].apply(compute_epoch_alert)\n",
    "    da = da[['userid','epoch']]\n",
    "    da['alert']=1\n",
    "    da.columns.values[0] = \"person_id\"\n",
    "    da.sort_values(['epoch'], ascending=[True])\n",
    "    \n",
    "    numb_total_alert=0\n",
    "    avg_alert_lag=0\n",
    "    stdv_alert_lag=0\n",
    "    da['lag']=(da['epoch']-da['epoch'].shift(1))/60.\n",
    "    da.loc[0,'lag']=240\n",
    "    numb_total_alert=da.shape[0]\n",
    "    avg_alert_lag=da['lag'].mean()\n",
    "    stdv_alert_lag=da['lag'].std()\n",
    "    print ('numb_total_alert=',numb_total_alert,'avg_alert_lag=',avg_alert_lag,'stdv_alert_lag=',stdv_alert_lag)\n",
    "    if(numb_total_alert>0):\n",
    "        #merge with feature vector to check the missing and hypoSG\n",
    "        #hypo-SG in 4-hr watch-up window after the alert being sent\n",
    "        dv = pd.read_csv(src+person_id+\"_hypofeature_kafka.csv\",dtype=object)\n",
    "        dv = dv[['userid','doNotPublish','doNotScore','sg_timestamp','hypo','dayofweek','hourofday','sglatest']]\n",
    "        dv['epoch']=dv['sg_timestamp'].apply(compute_epoch_vector)\n",
    "        dv.columns.values[0] = \"person_id\"\n",
    "        dv['hypoSG'] = np.where(pd.to_numeric(dv['sglatest'])>=80, 0, 1) #change to 70mgdL for more restricted rule\n",
    "        dv.sort_values(['epoch'], ascending=[True])\n",
    "        \n",
    "        #loop through each eligible alert\n",
    "        dd = da['epoch'].apply(check_watchup_drop_missing)\n",
    "        k= pd.DataFrame(dd.values.tolist(), index=dd.index)\n",
    "        k.columns = ['epoch','has_missing','pct_missing_watchup','hypoSG_watchup','first_hypoSG','leadtime_watchup']\n",
    "\n",
    "        pct_missing_watchup=k['pct_missing_watchup'].mean()\n",
    "        numb_alert_missingSG=len(k[k['pct_missing_watchup']>0].index)\n",
    "        print ('pct_missing_watchup=',pct_missing_watchup)\n",
    "        print ('numb_alert_missingSG=',numb_alert_missingSG)\n",
    "\n",
    "        dh = pd.merge(da,k,on=['epoch'],how='left')\n",
    "\n",
    "        #count the true negative alerts among alert having non-missing in watchup window\n",
    "        #dh.groupby('has_missing').size()\n",
    "        numb_alert_non_missingSG=len(dh[dh['has_missing']==0])\n",
    "        #less restricted rule to include missing SG cases\n",
    "        numb_fp_alert_org=len(dh[dh['hypoSG_watchup']==0])\n",
    "        FDR_org=numb_fp_alert_org/len(dh)*100\n",
    "        #more restricted rule to exclude missing SG cases\n",
    "        numb_fp_alert=len(dh[(dh['has_missing']==0) & (dh['hypoSG_watchup']==0)])\n",
    "        FDR=numb_fp_alert/numb_alert_non_missingSG*100\n",
    "        print ('numb_fp_alert_org=',numb_fp_alert_org,'numb_fp_alert=',numb_fp_alert,'numb_alert_non_missingSG=',numb_alert_non_missingSG, 'FDR_org=',FDR_org, 'FDR=',FDR)\n",
    "\n",
    "        #remove any alerts which is the hypoSG itself - its leadtime is 0\n",
    "        dk = dh[dh['leadtime_watchup']!=0]\n",
    "\n",
    "        #keep those ones having hypoSG found\n",
    "        dk1 = dk[dk['hypoSG_watchup']==1].reset_index()\n",
    "\n",
    "\n",
    "        #sort by first_hypoSG, and keep the earliest alert with the same first_hypoSG\n",
    "        pct_renew_tp_alert=np.nan\n",
    "        nonrenew_lag=np.nan\n",
    "        sum_leadtime=np.nan\n",
    "        numb_tp_alert=np.nan\n",
    "        avg_leadtime=np.nan\n",
    "        \n",
    "        if(dk1.shape[0]>0):\n",
    "            dk1['nonrenewlag']=(dk1['epoch']-dk1['epoch'].shift(1))/60.\n",
    "            dk1.loc[0,'nonrenewlag']=240\n",
    "            nonrenew_lag = dk1['nonrenewlag'].mean()\n",
    "            print('nonrenew_lag=',nonrenew_lag)\n",
    "\n",
    "            dk2 = dk1[['person_id','epoch','first_hypoSG','leadtime_watchup','hypoSG_watchup']].groupby('first_hypoSG').first().reset_index()\n",
    "\n",
    "            #renew alert among true positive alerts\n",
    "            pct_renew_tp_alert = (1-len(dk2)/len(dk1))*100\n",
    "            print('pct_renew_tp_alert=',pct_renew_tp_alert)\n",
    "\n",
    "            numb_tp_alert=len(dk2)\n",
    "            if(numb_tp_alert>0):\n",
    "                sum_leadtime=dk2['leadtime_watchup'].sum()\n",
    "                avg_leadtime=sum_leadtime/numb_tp_alert\n",
    "                print('avg_leadtime=',avg_leadtime,'numb_tp_alert=',numb_tp_alert)\n",
    "                \n",
    "    #print(person_id,numb_total_alert,avg_alert_lag,stdv_alert_lag,numb_alert_missingSG,pct_missing_watchup, \\\n",
    "          #numb_alert_non_missingSG,numb_fp_alert_org,FDR_org,numb_fp_alert,FDR, \\\n",
    "          #nonrenew_lag,pct_renew_tp_alert,numb_tp_alert,avg_leadtime)  \n",
    "            \n",
    "    dr = pd.DataFrame([[person_id,numb_total_alert,avg_alert_lag,stdv_alert_lag,numb_alert_missingSG,pct_missing_watchup, \\\n",
    "          numb_alert_non_missingSG,numb_fp_alert_org,FDR_org,numb_fp_alert,FDR, \\\n",
    "          nonrenew_lag,pct_renew_tp_alert,numb_tp_alert,avg_leadtime]],\n",
    "                      columns=['person_id','numb_total_alert','avg_alert_lag','stdv_alert_lag','numb_alert_missingSG','pct_missing_watchup', \\\n",
    "          'numb_alert_non_missingSG','numb_fp_alert_org','FDR_org','numb_fp_alert','FDR', \\\n",
    "          'nonrenew_lag','pct_renew_tp_alert','numb_tp_alert','avg_leadtime'])\n",
    "    print(dr)\n",
    "    dr.to_csv(dst+person_id+\"_leadtime_alternative.csv\", index=False, encoding='utf-8')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,3) (3,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-08c7e9609d85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# a.shape = (4, 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# b.shape = (3, 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,3) (3,2) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.randn(4, 3) # a.shape = (4, 3)\n",
    "b = np.random.randn(3, 2) # b.shape = (3, 2)\n",
    "c = a*b\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
